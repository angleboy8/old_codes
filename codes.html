<!DOCTYPE html>
<html>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-33433198-1']);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script><!--google tracker script-->

<head>
<meta charset="utf-8" />
<link rel="stylesheet" href="codes_files/style_codes.css" />
<title>codes - XAVIER BRESSON</title>
<style type="text/css">
a:active, a:focus {outline: none} <!--no dotted box after clicking on hyperlink-->
.wrapWithBackgroundImage
{background-image: url('codes_files/header_codes.jpg');}
.invisibleLink
{display: block; position: relative;} <!--hyperlink from background image-->
</style>
</head>

<header>
<div style="
width: 1024px;
height: 240px;
margin: 0px auto 0px auto;
background-image: url('codes_files/header_codes.jpg');
background-repeat: no-repeat;
background-position: center
">

</div> <!--end of navigation-->
</header>

<div style="
width: 1024px;
margin: 0px auto 0px auto
"> <!--corps-->

<article>
<div id="code">
    
    
    

<h1 id="nips13">Multiclass Total Variation Clustering&nbsp;&nbsp;&nbsp;&nbsp;
(2013)</h1>
<em>Description</em><br>
Ideas from the image processing literature have recently motivated a new set of clustering algorithms that rely on the concept of total variation. While these algorithms perform well for bi-partitioning tasks, their recursive extensions yield unimpressive results for multiclass clustering tasks. This paper presents a general framework for multiclass total variation clustering that does not rely on recursion. The results greatly outperform previous total variation algorithms and compare well with state-of-the-art NMF approaches.
<br><br>

<em>Related publication<br></em>
X. Bresson, T. Laurent, D. Uminsky and J.H. von Brecht, <em>"Multiclass Total Variation Clustering"</em>, arXiv:1302.2717, 2013&nbsp;&nbsp;&nbsp;&nbsp;
<a href="pub_files/xbresson_2013_nips.pdf" target="_blank">PDF</a><br><br>
<em>Keywords</em><br>
unsupervised data clustering, multi-class, Cheeger cut, spectral method, total variation, NMF <br><br>
<em>Code</em><br>
Matlab/C&nbsp;&nbsp;&nbsp;
<a href="codes_files/xbresson_2013_MTV_v2.zip" target="_blank">Lastest version</a>
&nbsp;&nbsp;&nbsp;
<a href="codes_files/xbresson_2013_MTV.zip" target="_blank">First version</a>
<br><br><br><img height="222" src="codes_files/2013_MTV.jpg" width="640"><br><br><br>
<div id="space"></div>





<h1 id="approxROFTVC">An Adaptive Total Variation Algorithm for Computing the Balanced Cut of a Graph&nbsp;&nbsp;&nbsp;&nbsp;
    (2013)</h1>
<em>Description</em><br>
We propose a novel algorithm that improves our NIPS12 algorithm "Convergence and Energy Landscape for Cheeger Cut Clustering" for solving the L1-relaxation of the Cheeger cut problem.
Our previous algorithm used a sequence of inner total variation minimizations to guarantee descent of the TV-Balanced cut energy as well as convergence of the algorithm.
In practice, the total variation minimization step is never solved exactly. Instead, an accuracy parameter is specified and the total variation minimization terminates once this level of accuracy is reached.
The choice of this parameter can vastly impact both the computational time of the overall algorithm as well as the accuracy of the result.
We introduce an adaptive stopping condition for the total variation minimization that still guarantees monotonicity of the algorithm.
This results is an algorithm that is actually monotonic in practice and proves to be twice faster on the MNIST benchmark database.
<br><br>

<em>Related publication<br></em>
X. Bresson, T. Laurent, D. Uminsky and J.H. von Brecht, <em>"An Adaptive Total Variation Algorithm for Computing the Balanced Cut of a Graph"</em>, arXiv:1302.2717, 2013&nbsp;&nbsp;&nbsp;&nbsp;
<a href="pub_files/xbresson_2013_arxivA.pdf" target="_blank">PDF</a><br><br>
<em>Keywords</em><br>
unsupervised data clustering, Cheeger cut, spectral method, continuous L1 relaxation, total variation, convergence analysis <br><br>
<em>Code</em><br>
Matlab/C&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2012_approxROF_TVC.zip" target="_blank">ZIP</a>
<br><br><br><img height="222" src="codes_files/2012_approxROFTVC.jpg" width="640"><br><br><br>
    <div id="space"></div>
    
    
    
    
    
    
    <h1 id="CSnormal">Enhanced Compressed Sensing Recovery With Level Set Normals&nbsp;&nbsp;&nbsp;&nbsp;
        (2013)</h1>
    <em>Description</em><br>
    We propose a compressive sensing algorithm that exploits geometric properties of images to recover images of high quality from few measurements. The image reconstruction is done by iterating the two following steps: 1) estimation of normal vectors of the image level curves, and 2) reconstruction of an image fitting the normal vectors, the compressed sensing measurements, and the sparsity constraint. The proposed technique can naturally extend to nonlocal operators and graphs to exploit the repetitive nature of textured images to recover fine detail structures. In both cases, the problem is reduced to a series of convex minimization problems that can be efficiently solved with a combination of variable splitting and augmented Lagrangian methods, leading to fast and easy-to-code algorithms. Extended experiments show a clear improvement over related state-of-the-art algorithms in the quality of the reconstructed images and the robustness of the proposed method to noise, different kind of images, and reduced measurements.<br><br>
    <em>Related publication<br></em>
    V. Estellers, J.P. Thiran and X. Bresson, <em>"Enhanced Compressed Sensing Recovery with Level Set Normals"</em>, IEEE Transactions on Image Processing, 22(7), 2611-2626, 2013&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="pub_files/xbresson_2013_tipC.pdf" target="_blank">PDF</a><br><br>
    <em>Keywords</em><br>
    Compressed sensing, image reconstruction, level sets, convex optimization<br><br>
    <em>Code</em><br>
    Matlab/C&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2013_CS_normal.zip" target="_blank">ZIP</a>
    <br><br><br><img height="222" src="codes_files/2013_cs.jpg" width="640"><br><br><br>
        <div id="space"></div>
        
        






<h1 id="nips12">Convergence and Energy Landscape for Cheeger Cut Clustering&nbsp;&nbsp;&nbsp;&nbsp; 
(2012)</h1>
<em>Description</em><br>
We introduce a new algorithm to solve the L1-relaxation of the Cheeger cut problem. The L2-relaxation, known as spectral clustering, only loosely relates to the Cheeger cut; however, it is convex and leads to a simple optimization problem. The L1-relaxation, in contrast, is non-convex but is provably equivalent to the original problem. The L1-relaxation therefore trades convexity for exactness, yielding improved clustering results at the cost of a more challenging optimization. The proposed L1 Cheeger algorithm is based on a steepest descent method that is guaranteed to converge. Experiments show that the proposed L1 Cheeger provides state-of-the-art results for unsupervised data clustering.<br><br>
<em>Related publication<br></em>
X. Bresson, T. Laurent, D. Uminsky and J.H. von Brecht, <em>"Convergence and Energy Landscape for Cheeger Cut Clustering"</em>, Annual Conference on Neural Information Processing Systems (NIPS), 2012&nbsp;&nbsp;&nbsp;&nbsp;
<a href="pub_files/xbresson_2012_nips.pdf" target="_blank">PDF</a><br><br>
<em>Keywords</em><br>
unsupervised data clustering, Cheeger cut, spectral method, continuous L1 relaxation, total variation, convergence analysis <br><br>
<em>Code</em><br>
Matlab/C&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2012_nips.zip" target="_blank">ZIP</a>
<br><br><br><img height="244" src="codes_files/2012_nips.jpg" width="639"><br><br><br>
<div id="space"></div>






<h1 id="sdf">An Efficient Algorithm for Level Set Method Preserving Distance Function&nbsp;&nbsp;&nbsp;&nbsp; 
(2012)</h1>
<em>Description</em><br>
We introduce a fast algorithm to preserve distance functions in level set methods. Our algorithm is inspired by recent efficient L1 optimization techniques, which will provide an efficient and easy to implement algorithm. It is interesting to note that our algorithm is not limited by the CFL condition and it naturally preserves the level set function as a distance function during the evolution, which avoids the classical re-distancing problem in level set methods. We apply the proposed algorithm to carry out image segmentation, where our methods proves to be 5 to 6 times faster than standard distance preserving level set techniques.<br><br>
<em>Related publication<br></em>
V. Estellers, D. Zosso, R. Lai, J.P. Thiran, S. Osher, X. Bresson, <em>"An Efficient Algorithm for Level Set Method Preserving Distance Function"</em>, IEEE Transactions on Image Processing, 2012&nbsp;&nbsp;&nbsp;&nbsp;
<a href="pub_files/xbresson_2012_tip.pdf" target="_blank">PDF</a><br><br>
<em>Keywords</em><br>
level set method, signed distance function, splitting method, convex optimization, total variation, image segmentation, surface reconstruction<br><br>
<em>Code</em><br>
Matlab/C&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2012_level_set_method_preserving_sdf.zip" target="_blank">ZIP</a>
<br><br><br><img height="540" src="codes_files/2012_lsm_preserving_sdf.jpg" width="640"><br><br><br>
<div id="space"></div>






<h1 id="learningmulti">Multi-Class Transductive Learning based on L1 Relaxations of Cheeger Cut and Mumford-Shah-Potts Model&nbsp;&nbsp;&nbsp;&nbsp; 
(2012)</h1>
<em>Description</em><br>
We introduce two multi-class transductive learning algorithms based on the L1 relaxation of the Cheeger cut and the Mumford-Shah-Potts models. Experiments show that the proposed L1 relaxation algorithms are more accurate than standard L2 relaxation methods s.a. spectral clustering, particularly when considering a very small number of labels for each class to be classified. For instance, the mean error of classification for the benchmark MNIST dataset of 60,000 data using the proposed L1 relaxation of the multi-class Cheeger cut is 2.4% when only one label is considered for each class, while the error of classification for the L2 relaxation method of spectral clustering is 24.7%.<br><br>
<em>Related publication<br></em>
X. Bresson, X.-C. Tai, T. F. Chan and A. Szlam, <em>"Multi-Class Transductive Learning based on L1 Relaxations of Cheeger Cut and Mumford-Shah-Potts Model"</em>, CAM report 12-03, 2012&nbsp;&nbsp;&nbsp;&nbsp;
<a href="pub_files/xbresson_2012_camA.pdf" target="_blank">PDF</a><br><br>
<em>Keywords</em><br>
data clustering, transductive learning, Cheeger, Mumford-Shah, Potts, spectral clustering, total variation, L1 relaxation, convex optimization<br><br>
<em>Code</em><br>
Matlab/C&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2012_multiclass_transductive_zip1.zip" target="_blank">ZIP 1</a>&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2012_multiclass_transductive_zip2.zip" target="_blank">ZIP 2</a>&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2012_multiclass_transductive_zip3.zip" target="_blank">ZIP 3</a>
<br><br><br><img height="297" src="codes_files/2012_learning_multiclass.jpg" width="640"><br><br><br>
<div id="space"></div>






<h1 id="watershed">Surface reconstruction using Power Watershed&nbsp;&nbsp;&nbsp;&nbsp; (2011)</h1>
<em>Description</em><br>
We define a surface reconstruction algorithm from a set of scattered points in 3D. We derive a Power Watershed algorithm to tackle this problem, which is fast, robust to markers placement, and produces smooth surfaces. Experiments show that the proposed algorithm compares favorably in terms of speed, memory requirement and accuracy with existing variational and discrete algorithms.<br><br>
<em>Related publication<br></em>
C. Couprie, X. Bresson, L. Najman, H. Talbot, L. Grady, <em>"Surface reconstruction using Power Watershed"</em>, International Symposium on Mathematical Morphology, 2011&nbsp;&nbsp;&nbsp;&nbsp;
<a href="pub_files/xbresson_2011_mmaisp.pdf" target="_blank">PDF</a><br><br>
<em>Keywords</em><br>
surface reconstruction, point measurements, graph-based optimization, graph cut method, total variation<br><br>
<em>Code</em><br>
Matlab/C&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2011_power_watershed_surf_reconstruction.zip" target="_blank">ZIP</a>
<br><br><br><img height="250" src="codes_files/2011_watershed.jpg" width="640"><br><br><br>
<div id="space"></div>






<h1 id="siims10">Bregmanized Nonlocal Regularization for Deconvolution and Sparse Reconstruction&nbsp;&nbsp;&nbsp;&nbsp;
    (2010)</h1>
<em>Description</em><br>
Bregman methods introduced in image processing are demonstrated to be an eﬃcient optimization method for solving sparse reconstruction with convex functionals, such as the L1 norm and total variation. In particular, the eﬃciency of this method relies on the performance of inner solvers for the resulting subproblems. We propose a general algorithm framework for inverse problem regularization with a single forward-backward operator splitting step, which is used to solve the subproblems of the Bregman iteration. We prove that the proposed algorithm, namely, Bregmanized operator splitting (BOS), converges without fully solving the subproblems. Furthermore, we apply the BOS algorithm and a preconditioned one for solving inverse problems with nonlocal functionals. Our numerical results on deconvolution and compressive sensing illustrate the performance of nonlocal total variation regularization under the proposed algorithm framework, compared to other regularization techniques such as the standard total variation method and the wavelet-based regularization method.<br><br>
<em>Related publication<br></em>
X. Zhang, M. Burger, X. Bresson, and S. Osher, <em>"Bregmanized Nonlocal Regularization for Deconvolution and Sparse Reconstruction"</em>, SIAM Journal on Imaging Sciences, 3(3), 253-276, 2010&nbsp;&nbsp;&nbsp;&nbsp;
<a href="pub_files/xbresson_2010_siims.pdf" target="_blank">PDF</a><br><br>
<em>Keywords</em><br>
compressed sensing, sparse optimization, Bregman iteration, primal-dual method, forward-backward method, nonlocal regularization <br><br>
<em>Code</em><br>
Matlab/C&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2010_sparse_opt.zip" target="_blank">ZIP</a>
<br><br><br><img height="250" src="codes_files/2010_sparse_opt.jpg" width="640"><br><br><br>
    <div id="space"></div>
    







<h1 id="nonloctvmini">An Algorithm for Nonlocal TV Minimization&nbsp;&nbsp;&nbsp;&nbsp; (2009)</h1>
<em>Description</em><br>
This is an algorithm to efficiently minimize the nonlocal Total Variation (NLTV) energy. The method is based on the Split-Bregman (SB), introduced by Goldstein-Osher, and extended to a nonlocal/graph version by Zhang-Burger-Bresson-Osher. For the 256x256 Barbara picture, the computation of weights takes around 1 second for a patch size 5x5 and a search window 11x11 and the NLTV minimization takes less than 2 seconds. So the total time for an image 256x256 for the NLTV minimization is less than 3 seconds. We also compare the SB version of NLTV with the dual version of NLTV, the NLH1, and the NL-Means. Experiments show that the SB-NLTV provides the best denoising result.<br><br>
<em>Note</em><br>
X. Bresson, <em>"A Short Note for Nonlocal TV Minimization"</em>, June 2009&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2009_short_note_nonlocal_TV_minimization.pdf" target="_blank">PDF</a><br><br>
<em>Related publication</em><br>
X. Zhang, M. Burger, X. Bresson, and S. Osher, <em>"Bregmanized Nonlocal Regularization for Deconvolution and Sparse Reconstruction"</em>, SIAM Journal on Imaging Sciences, 3(3), 253-276, 2010&nbsp;&nbsp;&nbsp;&nbsp;
<a href="pub_files/xbresson_2010_siims.pdf" target="_blank">PDF</a><br><br>
<em>Keywords</em><br>
image denoising, Nonlocal Total Variation (NLTV), Split-Bregman method, Comparisons with nonlocal H1, nonlocal Means<br><br>
<em>Code</em><br>
Matlab/C&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2009_NLTV.zip" target="_blank">ZIP</a>
<br><br><br><img height="250" src="codes_files/2009_barbara.jpg" width="640"><br><br><br>
    <div id="space"></div>
    
    
    
    
    
    
    <h1 id="wasser">Local Histogram Based Segmentation Using the Wasserstein Distance&nbsp;&nbsp;&nbsp;&nbsp; (2009)</h1>
    <em>Description</em><br>
    We propose a nonparametric region-based active contour model for segmenting cluttered scenes. The proposed model is unsupervised and assumes pixel intensity is independently identically distributed. Our proposed energy functional consists of a geometric regularization term that penalizes the length of the partition boundaries and a region-based image term that uses histograms of pixel intensity to distinguish different regions. More specifically, we use Wasserstein distance with exponent 1 to determine the dissimilarity between two histograms. The Wasserstein distance is a metric and is able to faithfully measure the distance between two histograms, compared to many pointwise distances. Moreover, it is insensitive to oscillations, and therefore our model is robust to noise. Eventually, our model does not required histogram differentiation.<br><br>
    <em>Related publication</em><br>
    K. Ni, X. Bresson, T. Chan and S. Esedoglu, <em>"Local Histogram Based Segmentation Using theWasserstein Distance"</em>, International Journal of Computer Vision, 84(1), 97-111, 2009&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="pub_files/xbresson_2009_ijcv.pdf" target="_blank">PDF</a><br><br>
    <em>Keywords</em><br>
    Image segmentation, unsupervised, Wasserstein distance, convex optimization, total variation<br><br>
    <em>Code</em><br>
    Matlab/C&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2009_wasserstein.zip" target="_blank">ZIP</a>
    <br><br><br><img height="250" src="codes_files/2009_wasser.jpg" width="640"><br><br><br>
        <div id="space"></div>
        
        
        
        


<h1 id="SB">A Fast Global Minimization Algorithm for Active Contour Models based on the Split-Bregman Method&nbsp;&nbsp;&nbsp;&nbsp; 
(2009)</h1>
<em>Description</em><br>
A fast global minimization algorithm is developed to minimize a large class of segmentation models called active contours. We believe that the proposed theory and algorithm produce so far one of the most efficient minimization methods for the active contour segmentation problem. For example, the well-know cameraman picture, which size is 256x256, is segmented in less than 0.1 seconds. Besides, our algorithm, while being easier to code, produces results slightly faster than the popular and fast graph-cuts technique. Our algorithm is also more accurate than graph-cuts because it uses isotropic schemes to regularize the contour and is sub-pixel accurate. Besides, the memory requirement is low. Finally, the reader can make fast its own active contour model. In the code, we emphasized the parts where the reader can add his/her own model.<br><br>
<em>Note</em><br>
X. Bresson, <em>"A Short Guide on a Fast Global Minimization Algorithm for Active Contour Models"</em>, 2009 &nbsp;&nbsp;<a href="codes_files/xbresson_2009_short_guide_global_active_contours.pdf" target="_blank">PDF</a><br><br>
<em>Related publication</em><br>
T. Goldstein, X. Bresson, and S. Osher, <em>"Geometric Applications of the Split Bregman Method: Segmentation and Surface Reconstruction"</em>, Journal of Scientific Computing, 45(1-3), 272-293, 2010&nbsp;&nbsp;&nbsp;&nbsp;
<a href="pub_files/xbresson_2010_jsc.pdf" target="_blank">PDF</a><br><br>
<em>Keywords</em><br>
segmentation, active contour, snake, global minimization, independence of initial position, ROF/TV model, Mumford-Shah energy, Chan-Vese model, fast minimization, Split-Bregman method, comparison with Graph-Cuts<br><br>
<em>Code</em><br>
Matlab/C&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2009_active_contour_splitBregman.zip" target="_blank">ZIP</a>
<br><br><br><img height="250" src="codes_files/2009_smooth.jpg" width="640"><br>
<br><br><br><img height="250" src="codes_files/2009_textures.jpg" width="640"><br><br><br>
<div id="space"></div>

<h1 id="acsp">Active Contour with Shape Prior&nbsp;&nbsp;&nbsp;&nbsp; (2008)</h1>
<em>Description</em><br>
We propose an implementation of the segmentation method proposed in the journal paper "A Variational Model for Object Segmentation Using Boundary Information and Shape Prior Driven by the Mumford-Shah Functional". The proposed segmentation algorithm combines the snake/geodesic active contour model with the Mumford-Shah model and constrains the shape in a family of forms provided by a principal component analysis (pca).<br><br>
<em>Related publication</em><br>
X. Bresson, P. Vandergheynst and J. Thiran, <em>"A Variational Model for Object Segmentation Using Boundary Information and Shape Prior Driven by the Mumford-Shah Functional"</em>, International Journal of Computer Vision (IJCV), Vol. 28, No 2, pp. 145 - 162, 2006 &nbsp;&nbsp;&nbsp; <a href="pub_files/xbresson_2006_ijcvB.pdf" target="_blank">PDF</a><br><br>
<em>Keywords</em><br>
segmentation, active contour, shape prior, principal component analysis/pca, level set method, Mumford-Shah model<br><br>
<em>Code</em><br>
Matlab/C&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2008_active_contour_shape_prior.zip" target="_blank">ZIP</a>
<br><br><br><img height="250" src="codes_files/2008_acsp1.jpg" width="640"><br>
<br><br><br><img height="250" src="codes_files/2008_acsp2.jpg" width="640"><br><br><br>
<div id="space"></div>

<h1 id="fastcolor">Fast Color Image Processing: Color Denoising and Color Deblurring&nbsp;&nbsp;&nbsp;&nbsp; 
(2007)</h1>
<em>Description</em><br>
We propose a regularization algorithm for color images which is fast, easy to code and mathematically well-posed. More precisely, the regularization model is based on the dual formulation of the vectorial total variation (VTV) norm and it may be regarded as the vectorial extension of the dual approach defined by Chambolle in 2004 for gray-scale images. The proposed model offers several advantages. First, it minimizes the exact VTV norm whereas standard approaches use a regularized norm. Then, the numerical scheme of minimization is straightforward to implement and finally, the number of iterations to reach the solution is low, which gives a fast regularization algorithm. Finally, and maybe more importantly, the proposed VTV minimization scheme can be easily extended to many standard imaging applications.<br><br>
<em>Related publication</em><br>
X. Bresson, T.F. Chan, <em>"Fast Dual Minimization of the Vectorial Total Variation Norm and Applications to Color Image Processing"</em>, Inverse Problems and Imaging, 2(4), 455-484, 2008&nbsp;&nbsp;&nbsp;&nbsp;
<a href="pub_files/xbresson_2008_ipi.pdf" target="_blank">PDF</a><br><br>
<em>Keywords</em><br>
vector-valued total variation, dual optimization, image denoising, Rudin-Osher-Fatemi model<br><br>
<em>Code</em><br>
Matlab/C for Color Denoising&nbsp;&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2007_color_denoising_rof.zip" target="_blank">ZIP</a><br>
Matlab/C for Color Deblurring&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2007_color_deblurring_rof.zip" target="_blank">ZIP</a>
<br><br><br><img height="300" src="codes_files/2007_dualtvnd_rose.jpg" width="640"><br>
<br><br><br><img height="300" src="codes_files/2007_deblurring.jpg" width="640"><br><br><br>
<div id="space"></div>

<h1 id="glomini">A Global Minimization of the Active Contour Model based on Chambolle's Projection Algorithm&nbsp;&nbsp;&nbsp;&nbsp; 
(2007)</h1>
<em>Description</em><br>
The active contour/snake model is one of the most successful variational models in image segmentation. The only drawback of this model is the existence of local minima in the active contour energy, which makes the initial guess critical to get satisfactory results. We introduce an algorithm that determines a global minimizer of the active contour model. Our approach is based on the unification of image segmentation and image denoising tasks into a global minimization framework. From a numerical point of view, we propose a new practical way to solve the active contour propagation problem through a dual formulation of the minimization problem. The dual formulation, easy to implement, allows us a fast global minimization of the snake energy. It avoids the usual drawback in the level set approach that consists of initializing the active contour in a distance function and re-initializing it periodically during the evolution, which is time-consuming.<br><br>
<em>Related publication</em><br>
X. Bresson, S. Esedoglu, P. Vandergheynst, J. Thiran and S. Osher, <em>"Fast Global Minimization of the Active Contour/Snake Model"</em>, Journal of Mathematical Imaging and Vision, 2007 &nbsp;&nbsp;&nbsp; <a href="pub_files/xbresson_2007_jmiv.pdf" target="_blank">PDF</a><br><br>
<em>Keywords</em><br>
active contour, global optimization, weighted total variation norm, Rudin-Osger-Fatemi model, Mumford-Shah energy, dual formulation of total variation<br><br>
<em>Code</em><br>
Matlab/C&nbsp;&nbsp;&nbsp; <a href="codes_files/xbresson_2007_active_contour_global_minimizer.zip" target="_blank">ZIP</a>
<br><br><br><img height="540" src="codes_files/2007_gmac.jpg" width="640"><br><br><br>
</div> <!--end of code-->




</article>


<footer>
    <div id="space"></div>
    <div id="copyright"><strong>© 2014 Xavier Bresson</strong></div>
    <div id="address">University of Lausanne, Rue du Bugnon 46, CH-1011 Lausanne, Switzerland</div>
    <div id="phone">Phone: + 4176 748 0538</div>
    <div id="email">Email: <a href="mailto:xavier.bresson@unil.ch">xavier.bresson@unil.ch</a></div>
</footer>

</div> <!--end of corps-->

</html>